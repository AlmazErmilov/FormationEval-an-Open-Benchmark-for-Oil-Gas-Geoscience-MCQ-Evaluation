% References for FormationEval paper

@article{mmlu,
  title = {Measuring Massive Multitask Language Understanding},
  author = {Hendrycks, Dan and Burns, Collin and Basart, Steven and Zou, Andy and Mazeika, Mantas and Song, Dawn and Steinhardt, Jacob},
  journal = {arXiv preprint arXiv:2009.03300},
  year = {2021},
  url = {https://arxiv.org/abs/2009.03300}
}

@article{arc,
  title = {Think you have Solved Question Answering? Try ARC, the AI2 Reasoning Challenge},
  author = {Clark, Peter and Cowhey, Isaac and Etzioni, Oren and Khot, Tushar and Sabharwal, Ashish and Schoenick, Carissa and Tafjord, Oyvind},
  journal = {arXiv preprint arXiv:1803.05457},
  year = {2018},
  url = {https://arxiv.org/abs/1803.05457}
}

@book{ellis_singer_2007,
  title = {Well Logging for Earth Scientists},
  author = {Ellis, Darwin V. and Singer, Julian M.},
  year = {2007},
  edition = {2nd},
  publisher = {Springer},
  address = {Dordrecht},
  isbn = {978-1-4020-4602-5},
  doi = {10.1007/978-1-4020-4602-5},
  url = {https://doi.org/10.1007/978-1-4020-4602-5}
}

@book{bjorlykke_2010,
  title = {Petroleum Geoscience: From Sedimentary Environments to Rock Physics},
  author = {Bj{\o}rlykke, Knut},
  year = {2010},
  publisher = {Springer},
  address = {Berlin},
  isbn = {978-3-642-02332-3},
  doi = {10.1007/978-3-642-02332-3},
  url = {https://doi.org/10.1007/978-3-642-02332-3}
}

@misc{tudelft_ocw_2008,
  title = {Petroleum Geology},
  author = {{TU Delft OpenCourseWare}},
  year = {2008},
  howpublished = {\url{https://ocw.tudelft.nl/courses/petroleum-geology/}},
  note = {Accessed December 2025}
}

@misc{formationeval_repo,
  title = {{FormationEval}: An Open Benchmark for Oil and Gas Geoscience {MCQ} Evaluation},
  author = {Ermilov, Almaz},
  year = {2025},
  howpublished = {\url{https://github.com/AlmazErmilov/FormationEval-an-Open-Benchmark-for-Oil-Gas-Geoscience-MCQ-Evaluation}},
  note = {Repository with benchmark data and evaluation code. Accessed December 2025}
}

@misc{formationeval_dataset,
  title = {{FormationEval} v0.1 Dataset},
  author = {Ermilov, Almaz},
  year = {2025},
  howpublished = {\url{https://github.com/AlmazErmilov/FormationEval-an-Open-Benchmark-for-Oil-Gas-Geoscience-MCQ-Evaluation/blob/main/data/benchmark/formationeval_v0.1.json}},
  note = {505 MCQs in JSON format with provenance metadata. Accessed December 2025}
}

% Wilson confidence interval reference
@article{wilson_ci,
  title = {Probable Inference, the Law of Succession, and Statistical Inference},
  author = {Wilson, Edwin B.},
  journal = {Journal of the American Statistical Association},
  volume = {22},
  number = {158},
  pages = {209--212},
  year = {1927},
  doi = {10.1080/01621459.1927.10502953},
  url = {https://doi.org/10.1080/01621459.1927.10502953}
}

% =============================================================================
% API Providers
% =============================================================================

@misc{azure_openai,
  title = {{Azure OpenAI Service} Documentation},
  author = {{Microsoft}},
  year = {2025},
  howpublished = {\url{https://learn.microsoft.com/en-us/azure/ai-services/openai/}},
  note = {Accessed December 2025}
}

@misc{openrouter,
  title = {{OpenRouter}: Unified API for {AI} Models},
  author = {{OpenRouter}},
  year = {2025},
  howpublished = {\url{https://openrouter.ai/docs}},
  note = {Accessed December 2025}
}

% =============================================================================
% Model Technical Reports and Model Cards
% =============================================================================

% Alibaba - Qwen
@article{qwen3,
  title = {Qwen3 Technical Report},
  author = {{Qwen Team}},
  journal = {arXiv preprint arXiv:2505.09388},
  year = {2025},
  url = {https://arxiv.org/abs/2505.09388}
}

% Anthropic - Claude
@misc{claude3,
  title = {The {Claude} 3 Model Family: Opus, Sonnet, Haiku},
  author = {{Anthropic}},
  year = {2024},
  howpublished = {\url{https://www-cdn.anthropic.com/de8ba9b01c9ab7cbabf5c33b80b7bbc618857627/Model_Card_Claude_3.pdf}},
  note = {Model card. Accessed December 2025}
}

@misc{claude35,
  title = {Model Card Addendum: {Claude} 3.5 Haiku and Upgraded {Claude} 3.5 Sonnet},
  author = {{Anthropic}},
  year = {2024},
  howpublished = {\url{https://assets.anthropic.com/m/1cd9d098ac3e6467/original/Claude-3-Model-Card-October-Addendum.pdf}},
  note = {Model card addendum. Accessed December 2025}
}

@misc{claude37,
  title = {{Claude} 3.7 Sonnet System Card},
  author = {{Anthropic}},
  year = {2025},
  howpublished = {\url{https://www.anthropic.com/claude-3-7-sonnet-system-card}},
  note = {System card. Accessed December 2025}
}

@misc{claude_opus45,
  title = {{Claude} Opus 4.5 System Card},
  author = {{Anthropic}},
  year = {2025},
  howpublished = {\url{https://www.anthropic.com/claude-opus-4-5-system-card}},
  note = {System card. Accessed December 2025}
}

% DeepSeek
@article{deepseek_v3,
  title = {{DeepSeek-V3} Technical Report},
  author = {{DeepSeek-AI}},
  journal = {arXiv preprint arXiv:2412.19437},
  year = {2024},
  url = {https://arxiv.org/abs/2412.19437}
}

@misc{deepseek_v3_2,
  title = {{DeepSeek-V3.2} Model Card},
  author = {{DeepSeek-AI}},
  year = {2025},
  howpublished = {\url{https://huggingface.co/deepseek-ai/DeepSeek-V3.2}},
  note = {Hugging Face model card. Accessed December 2025}
}

@article{deepseek_r1,
  title = {{DeepSeek-R1}: Incentivizing Reasoning Capability in {LLMs} via Reinforcement Learning},
  author = {{DeepSeek-AI}},
  journal = {arXiv preprint arXiv:2501.12948},
  year = {2025},
  url = {https://arxiv.org/abs/2501.12948}
}

% Google - Gemini
@article{gemini,
  title = {Gemini: A Family of Highly Capable Multimodal Models},
  author = {{Gemini Team, Google}},
  journal = {arXiv preprint arXiv:2312.11805},
  year = {2023},
  url = {https://arxiv.org/abs/2312.11805}
}

@misc{gemini2,
  title = {Gemini 2 Flash Model Card},
  author = {{Google DeepMind}},
  year = {2025},
  howpublished = {\url{https://modelcards.withgoogle.com/assets/documents/gemini-2-flash.pdf}},
  note = {Model card. Accessed December 2025}
}

@article{gemini25,
  title = {Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities},
  author = {{Gemini Team, Google DeepMind}},
  journal = {arXiv preprint arXiv:2507.06261},
  year = {2025},
  url = {https://arxiv.org/abs/2507.06261}
}

@misc{gemini3,
  title = {Gemini 3 Pro Model Card},
  author = {{Google DeepMind}},
  year = {2025},
  howpublished = {\url{https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-3-Pro-Model-Card.pdf}},
  note = {Model card. Accessed December 2025}
}

% Google - Gemma
@misc{gemma3,
  title = {Gemma 3 Model Card},
  author = {{Google DeepMind}},
  year = {2025},
  howpublished = {\url{https://ai.google.dev/gemma/docs/core/model_card_3}},
  note = {Accessed December 2025}
}

% Meta - Llama
@article{llama3,
  title = {The {Llama} 3 Herd of Models},
  author = {{Llama Team, AI @ Meta}},
  journal = {arXiv preprint arXiv:2407.21783},
  year = {2024},
  url = {https://arxiv.org/abs/2407.21783}
}

@misc{llama31,
  title = {{Llama} 3.1 Model Card},
  author = {{Meta}},
  year = {2024},
  howpublished = {\url{https://github.com/meta-llama/llama-models/blob/main/models/llama3_1/MODEL_CARD.md}},
  note = {Model card. Accessed December 2025}
}

@misc{llama32,
  title = {{Llama} 3.2 Model Card},
  author = {{Meta}},
  year = {2024},
  howpublished = {\url{https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD.md}},
  note = {Model card. Accessed December 2025}
}

@misc{llama4,
  title = {{Llama} 4 Model Card},
  author = {{Meta}},
  year = {2025},
  howpublished = {\url{https://github.com/meta-llama/llama-models/blob/main/models/llama4/MODEL_CARD.md}},
  note = {GitHub model card. Accessed December 2025}
}

% Microsoft - Phi
@article{phi4,
  title = {Phi-4 Technical Report},
  author = {Abdin, Marah and Aneja, Jyoti and Behl, Harkirat and Bubeck, S{\'e}bastien and Eldan, Ronen and Gunasekar, Suriya and Harrison, Michael and Hewett, Russell and Javaheripi, Mojan and Kauffmann, Piero and others},
  journal = {arXiv preprint arXiv:2412.08905},
  year = {2024},
  url = {https://arxiv.org/abs/2412.08905}
}

% MiniMax
@misc{minimax_m2,
  title = {{MiniMax-M2}: A Model Built for Max Coding and Agentic Workflows},
  author = {{MiniMax}},
  year = {2025},
  howpublished = {\url{https://huggingface.co/MiniMaxAI/MiniMax-M2}},
  note = {Hugging Face model card. Accessed December 2025}
}

% Mistral AI
@misc{mistral,
  title = {Mistral {AI} Models},
  author = {{Mistral AI}},
  year = {2025},
  howpublished = {\url{https://docs.mistral.ai/getting-started/models/}},
  note = {Model documentation. Accessed December 2025}
}

% Moonshot AI - Kimi
@article{kimi_k2,
  title = {{Kimi K2}: Open Agentic Intelligence},
  author = {{Moonshot AI}},
  journal = {arXiv preprint arXiv:2507.20534},
  year = {2025},
  url = {https://arxiv.org/abs/2507.20534}
}

% Nvidia - Nemotron
@misc{nemotron,
  title = {{Nemotron}: Foundation Models for Agentic {AI}},
  author = {{NVIDIA}},
  year = {2025},
  howpublished = {\url{https://developer.nvidia.com/nemotron}},
  note = {Accessed December 2025}
}

% OpenAI - GPT series
@article{gpt4,
  title = {{GPT-4} Technical Report},
  author = {{OpenAI}},
  journal = {arXiv preprint arXiv:2303.08774},
  year = {2023},
  url = {https://arxiv.org/abs/2303.08774}
}

@article{gpt4o,
  title = {{GPT-4o} System Card},
  author = {{OpenAI}},
  journal = {arXiv preprint arXiv:2410.21276},
  year = {2024},
  url = {https://arxiv.org/abs/2410.21276}
}

@misc{gpt41,
  title = {Introducing {GPT-4.1} in the {API}},
  author = {{OpenAI}},
  year = {2025},
  howpublished = {\url{https://openai.com/index/gpt-4-1/}},
  note = {Accessed December 2025}
}

@misc{gpt5,
  title = {{GPT-5} System Card},
  author = {{OpenAI}},
  year = {2025},
  howpublished = {\url{https://cdn.openai.com/gpt-5-system-card.pdf}},
  note = {System card. Accessed December 2025}
}

@misc{o3_o4mini,
  title = {{OpenAI} o3 and o4-mini System Card},
  author = {{OpenAI}},
  year = {2025},
  howpublished = {\url{https://cdn.openai.com/pdf/2221c875-02dc-4789-800b-e7758f3722c1/o3-and-o4-mini-system-card.pdf}},
  note = {System card. Accessed December 2025}
}

% xAI - Grok
@misc{grok3,
  title = {Grok 3 Model Page},
  author = {{OpenRouter}},
  year = {2025},
  howpublished = {\url{https://openrouter.ai/x-ai/grok-3}},
  note = {Model page. Accessed December 2025}
}

@misc{grok,
  title = {Grok 4 Model Card},
  author = {{xAI}},
  year = {2025},
  howpublished = {\url{https://data.x.ai/2025-08-20-grok-4-model-card.pdf}},
  note = {Model card. Accessed December 2025}
}

% Zhipu AI - GLM
@article{glm4,
  title = {{ChatGLM}: A Family of Large Language Models from {GLM-130B} to {GLM-4} All Tools},
  author = {{GLM Team, Zhipu AI}},
  journal = {arXiv preprint arXiv:2406.12793},
  year = {2024},
  url = {https://arxiv.org/abs/2406.12793}
}

@misc{glm47,
  title = {{GLM-4.7} Model Card},
  author = {{Zhipu AI}},
  year = {2025},
  howpublished = {\url{https://huggingface.co/zai-org/GLM-4.7}},
  note = {Hugging Face model card. Accessed December 2025}
}
